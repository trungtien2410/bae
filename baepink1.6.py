from PyQt6 import QtCore, QtGui, QtWidgets
import pandas as pd
from datetime import timedelta
import sys
import os
from pathlib import Path
import unicodedata
import re
from fuzzywuzzy import fuzz
import shutil
import subprocess
import requests
import json
import semver
import tempfile
import time

# --- APPLICATION VERSION & UPDATE CONFIGURATION ---
# IMPORTANT: Update this version with each new release!
APP_VERSION = "1.2.0" 

# URL to your version.txt file on GitHub (raw content)
VERSION_URL = "https://raw.githubusercontent.com/trungtien2410/hang-ra-quay/main/version.txt"

# This assumes your executable name is consistent in GitHub releases.
# For example, if your GitHub release tag is 'V1.2.0', and the asset is 'hang-ra-quay-ver2.4.exe',
# then UPDATE_EXECUTABLE_NAME should be 'hang-ra-quay-ver2.4.exe'.
UPDATE_EXECUTABLE_NAME = "hang-ra-quay-ver2.4.exe" 

# Helper function to construct the download URL based on the latest version tag.
# This assumes your GitHub releases follow the pattern:
# https://github.com/trungtien2410/hang-ra-quay/releases/download/{TAG_NAME}/{ASSET_NAME}
# where TAG_NAME might be 'V1.2.0' if version.txt contains '1.2.0'.
# We will prepend 'V' to the version from version.txt to form the tag name.
def get_download_url(latest_version_from_txt):
    # Ensure the tag format matches your GitHub release tags (e.g., 'V1.2.0' for version '1.2.0')
    tag_name = f"V{latest_version_from_txt}" 
    return f"https://github.com/trungtien2410/hang-ra-quay/releases/download/{tag_name}/{UPDATE_EXECUTABLE_NAME}"

# --- Update-specific QThreads ---

class CheckUpdateThread(QtCore.QThread):
    """Checks for the latest version from VERSION_URL."""
    check_finished = QtCore.pyqtSignal(bool, str) # success, latest_version_string or error_message

    def run(self):
        try:
            response = requests.get(VERSION_URL, timeout=5)
            response.raise_for_status() # Raise an exception for HTTP errors
            latest_version = response.text.strip()
            self.check_finished.emit(True, latest_version)
        except requests.exceptions.RequestException as e:
            self.check_finished.emit(False, f"L·ªói m·∫°ng khi ki·ªÉm tra c·∫≠p nh·∫≠t: {e}")
        except Exception as e:
            self.check_finished.emit(False, f"L·ªói kh√¥ng mong mu·ªën khi ki·ªÉm tra c·∫≠p nh·∫≠t: {e}")

class DownloadUpdateThread(QtCore.QThread):
    """Downloads the update file and emits progress and status."""
    download_progress = QtCore.pyqtSignal(int, str) # percentage, status_text
    download_finished = QtCore.pyqtSignal(str) # Path to downloaded file
    download_error = QtCore.pyqtSignal(str) # Error message

    def __init__(self, latest_version_tag):
        super().__init__()
        self.latest_version_tag = latest_version_tag
        self._is_canceled = False

    def run(self):
        try:
            update_url = get_download_url(self.latest_version_tag)
            
            # This initial message will show up in the progress dialog
            self.download_progress.emit(0, f"üöÄ ƒêang t·∫£i b·∫£n c·∫≠p nh·∫≠t...\n"
                                           f"‚¨á Chu·∫©n b·ªã t·∫£i t·ª´: {update_url.split('//')[1].split('/')[0]}...")

            r = requests.get(update_url, stream=True, timeout=300) # 5-minute timeout
            r.raise_for_status()

            total_size = int(r.headers.get('content-length', 0))
            block_size = 8192 # 8KB chunks (common buffer size)
            temp_dir = tempfile.gettempdir()
            file_path = Path(temp_dir) / UPDATE_EXECUTABLE_NAME 

            downloaded = 0
            start_time = time.time()
            with open(file_path, 'wb') as f:
                for chunk in r.iter_content(block_size):
                    if self._is_canceled: # Check for cancellation request
                        raise UserCancelledDownload("Download was cancelled by user.")
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        percent = int(downloaded * 100 / total_size) if total_size > 0 else 0
                        
                        elapsed = time.time() - start_time
                        speed_bps = downloaded / elapsed if elapsed > 0 else 0
                        speed_mbps = speed_bps / (1024 * 1024)
                        
                        remaining_bytes = total_size - downloaded
                        remaining_time_sec = remaining_bytes / speed_bps if speed_bps > 0 else 0

                        status_text = (
                            f"üöÄ ƒêang t·∫£i... {percent}%\n"
                            f"‚¨á {downloaded // (1024 * 1024)} MB / {total_size // (1024 * 1024)} MB "
                            f"({speed_mbps:.2f} MB/s)\n"
                            f"‚è≥ C√≤n l·∫°i: {int(remaining_time_sec)}s"
                        )
                        self.download_progress.emit(percent, status_text)
            
            self.download_finished.emit(str(file_path))

        except UserCancelledDownload:
            self.download_error.emit("ƒê√£ h·ªßy c·∫≠p nh·∫≠t.")
            if 'file_path' in locals() and os.path.exists(file_path):
                os.remove(file_path) # Clean up partial download
        except requests.exceptions.RequestException as e:
            self.download_error.emit(f"L·ªói m·∫°ng khi t·∫£i b·∫£n c·∫≠p nh·∫≠t: {e}")
            if 'file_path' in locals() and os.path.exists(file_path):
                os.remove(file_path) # Clean up partial download
        except Exception as e:
            self.download_error.emit(f"L·ªói kh√¥ng mong mu·ªën khi t·∫£i b·∫£n c·∫≠p nh·∫≠t: {e}")
            if 'file_path' in locals() and os.path.exists(file_path):
                os.remove(file_path) # Clean up partial download

    def requestInterruption(self):
        self._is_canceled = True

class UserCancelledDownload(Exception):
    """Custom exception for user canceling download."""
    pass


def resource_path(relative_path):
    """
    L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn m·ªôt t√†i nguy√™n, x·ª≠ l√Ω c·∫£ m√¥i tr∆∞·ªùng ph√°t tri·ªÉn v√† m√¥i tr∆∞·ªùng ƒë√£ ƒë√≥ng g√≥i b·∫±ng PyInstaller.
    """
    if hasattr(sys, '_MEIPASS'):
        return str(Path(sys._MEIPASS) / relative_path)
    else:
        return str(Path(__file__).parent / relative_path)

class Worker(QtCore.QThread):
    """
    L·ªõp con c·ªßa QThread ƒë·ªÉ th·ª±c hi·ªán vi·ªác c·∫°o d·ªØ li·ªáu web v√† t·∫°o t√†i li·ªáu Excel trong m·ªôt lu·ªìng ri√™ng bi·ªát.
    Ph√°t t√≠n hi·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô, th√¥ng b√°o nh·∫≠t k√Ω v√† tr·∫°ng th√°i ho√†n th√†nh.
    """
    progress = QtCore.pyqtSignal(int)
    log = QtCore.pyqtSignal(str)
    finished = QtCore.pyqtSignal(object)

    def __init__(self, input_file_path, output_file_path):
        """
        Kh·ªüi t·∫°o lu·ªìng Worker.
        Args:
            input_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel ƒë·∫ßu v√†o.
            output_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file Excel k·∫øt qu·∫£.
        """
        super().__init__()
        self.input_file_path = input_file_path
        self.output_file_path = output_file_path

    def run(self):
        try:
            self.log.emit("‚ÑπÔ∏è ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ file...")
            # Get the file extension
            file_extension = os.path.splitext(self.input_file_path)[1].lower()
            if file_extension in ['.xlsx', '.xls']:
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file Excel. ƒêang ƒë·ªçc...")
                self.data = pd.read_excel(self.input_file_path, engine='openpyxl')
            elif file_extension == '.csv':
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file CSV. ƒêang ƒë·ªçc...")
                # You might want to add encoding='utf-8' or other encoding if you encounter issues
                self.data = pd.read_csv(self.input_file_path)
            else:
                self.log.emit(f"‚ùå L·ªói: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}. Vui l√≤ng ch·ªçn file Excel (.xlsx, .xls) ho·∫∑c CSV (.csv).")
                self.finished.emit(None)
                return


            self.df = pd.DataFrame(self.data)
            self.df['buyer_id'] = self.df['buyer_id'].drop_duplicates()
            drop_column = ["grass_hour","create_time","order_id","item_name","seller_id","shop_name","status_b","buyer_user_name","buyer_email","recipient_phone_","recipient_name","buyer_shipping_address","buyer_shipping_address_district","buyer_shipping_address_city","buyer_shipping_address_state","address_modified_time_latest","sz_device","ip_checkout","gmv_vnd","pv_promotion_id","pv_promotion_cap","pv_promotion_name","pv_voucher_code","pv_rebate_by_shopee_vnd","is_nuv","sv_promotion_id","sv_voucher_code","coin_earn","coin_used_cash_amt","fsv_voucher_code","is_fsv_nuv","origin_shipping_fee_vnd","item_rebate_vnd","item_id","is_buyer_legit","is_seller_cb_seller","is_seller_official_shop","is_seller_preferred_seller","order_sn","buyer_cancel_reason"]
            # Validate required columns
            self.df = self.df.drop(columns=drop_column, errors='ignore')
            required_columns = ['N3', 'registration_time', 'buyer_id']
            if not all(col in self.df.columns for col in required_columns):
                missing_cols = [col for col in required_columns if col not in self.df.columns]
                self.log.emit(f"‚ùå L·ªói: File Excel thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing_cols)}")
                self.finished.emit(None)
                return

            self.log.emit("‚ÑπÔ∏è ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
            # X·ª≠ l√Ω c·ªôt restristration_time xo√° c√°c d√≤ng NaT v√† chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
            self.df['registration_time'].dropna(inplace=True) 
            # ƒê·∫£m b·∫£o c·ªôt 'registration_time' l√† ki·ªÉu datetime
            self.df['registration_time'] = pd.to_datetime(self.df['registration_time'], errors='coerce')
            
            # Filter out rows where registration_time is NaT (invalid date)
            df_filtered = self.df.dropna(subset=['registration_time']).copy()
            
            # Sort by phone number and time for optimized searching
            df_sorted = df_filtered.sort_values(by=['N3', 'registration_time']).reset_index(drop=True)

            final_grouped_ids = set() # To store all unique IDs that belong to any valid group
            
            total_phone_nums = len(df_sorted['N3'].unique())
            processed_phone_nums = 0

            # Iterate through each unique phone number group
            for phone_num, group in df_sorted.groupby('N3'):
                processed_phone_nums += 1
                self.progress.emit(int((processed_phone_nums / total_phone_nums) * 100))

                # Convert group to a list of dictionaries for easier indexing and manipulation
                phone_records = group.to_dict('records')
                
                i = 0 # 'i' is the starting index of the current potential group
                while i < len(phone_records):
                    current_group_ids = []
                    current_group_times = []

                    # Start a new potential group with the current record (the "m·ªëc ƒë·∫ßu ti√™n")
                    start_record = phone_records[i]
                    current_group_ids.append(start_record['buyer_id'])
                    current_group_times.append(start_record['registration_time'])
                    
                    # 'last_time_in_group' tracks the time of the latest record added to the current group.
                    # This is the "m·ªëc" for checking the 1-hour window for subsequent records.
                    last_time_in_group = start_record['registration_time']

                    # 'j' iterates through subsequent records to expand the current group
                    j = i + 1
                    while j < len(phone_records):
                        next_record = phone_records[j]
                        next_id = next_record['buyer_id']
                        next_time = next_record['registration_time']

                        # Check if the 'next_time' is within 1 hour of the 'last_time_in_group'
                        if (next_time - last_time_in_group) <= timedelta(hours=1):
                            current_group_ids.append(next_id)
                            current_group_times.append(next_time)
                            j += 1
                        else:
                            # If the time gap is too large, stop extending the current group
                            break 
                    
                    # "√≠t nh·∫•t 3 con ri√™ng bi·ªát" -> len(set(current_group_ids)) >= 3
                    unique_ids_in_group = set(current_group_ids)
                    if len(unique_ids_in_group) >= 3:
                        final_grouped_ids.update(unique_ids_in_group)
                    # Move 'i' to the next record after the current group
                    i += 1
            
                    
            self.log.emit("‚ÑπÔ∏è ƒêang l∆∞u k·∫øt qu·∫£...")
            
            # Create a DataFrame for the final grouped IDs (single column)
            if final_grouped_ids:
                df_output_ids = pd.DataFrame(list(final_grouped_ids), columns=['ID'])
                df_output_ids.to_excel(self.output_file_path, index=False, engine='openpyxl')
                self.log.emit(f"‚úÖ ƒê√£ l∆∞u danh s√°ch ID nh√≥m t·∫°i: {self.output_file_path}")
            else:
                self.log.emit("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y ID n√†o ƒë·ªÉ nh√≥m theo ti√™u ch√≠ (√≠t nh·∫•t 3 ID ri√™ng bi·ªát trong 1 gi·ªù).")
            
            self.finished.emit(True) # Indicate successful completion
            
        except FileNotFoundError:
            self.log.emit(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file Excel t·∫°i ƒë∆∞·ªùng d·∫´n: {self.input_file_path}")
            self.finished.emit(None)
        except Exception as e:
            self.log.emit(f"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
            self.finished.emit(None)

class Worker2(QtCore.QThread):
    """
    L·ªõp con c·ªßa QThread ƒë·ªÉ th·ª±c hi·ªán vi·ªác c·∫°o d·ªØ li·ªáu web v√† t·∫°o t√†i li·ªáu Word trong m·ªôt lu·ªìng ri√™ng bi·ªát.
    Ph√°t t√≠n hi·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô, th√¥ng b√°o nh·∫≠t k√Ω v√† tr·∫°ng th√°i ho√†n th√†nh.
    """
    progress = QtCore.pyqtSignal(int)
    log = QtCore.pyqtSignal(str)
    finished = QtCore.pyqtSignal(object)

    def __init__(self, input_file_path, output_file_path):
        """
        Kh·ªüi t·∫°o lu·ªìng Worker.
        Args:
            input_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel ƒë·∫ßu v√†o.
            output_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file Excel k·∫øt qu·∫£.
        """
        super().__init__()
        self.input_file_path = input_file_path
        self.output_file_path = output_file_path

    def run(self):
        try:
            self.log.emit("‚ÑπÔ∏è ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ file...")
            # Get the file extension
            file_extension = os.path.splitext(self.input_file_path)[1].lower()
            if file_extension in ['.xlsx', '.xls']:
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file Excel. ƒêang ƒë·ªçc...")
                self.data = pd.read_excel(self.input_file_path, engine='openpyxl')
            elif file_extension == '.csv':
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file CSV. ƒêang ƒë·ªçc...")
                # You might want to add encoding='utf-8' or other encoding if you encounter issues
                self.data = pd.read_csv(self.input_file_path)
            else:
                self.log.emit(f"‚ùå L·ªói: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}. Vui l√≤ng ch·ªçn file Excel (.xlsx, .xls) ho·∫∑c CSV (.csv).")
                self.finished.emit(None)
                return
            self.df = pd.DataFrame(self.data)
            # self.df['buyer_id'] = self.df['buyer_id'].drop_duplicates()
            drop_column = ["grass_hour","create_time","order_id","item_name","seller_id","shop_name","status_b","buyer_user_name","buyer_email","recipient_name","buyer_shipping_address","buyer_shipping_address_district","buyer_shipping_address_city","buyer_shipping_address_state","address_modified_time_latest","sz_device","ip_checkout","gmv_vnd","pv_promotion_cap","pv_promotion_name","pv_voucher_code","pv_rebate_by_shopee_vnd","is_nuv","sv_promotion_id","sv_voucher_code","coin_earn","coin_used_cash_amt","fsv_voucher_code","is_fsv_nuv","origin_shipping_fee_vnd","item_rebate_vnd","item_id","is_buyer_legit","is_seller_cb_seller","is_seller_official_shop","is_seller_preferred_seller","order_sn","buyer_cancel_reason"]
            self.df = self.df.drop(columns=drop_column, errors='ignore')
            # Validate required columns
            required_columns = ['recipient_phone_', 'pv_promotion_id', 'buyer_id']
            if not all(col in self.df.columns for col in required_columns):
                missing_cols = [col for col in required_columns if col not in self.df.columns]
                self.log.emit(f"‚ùå L·ªói: File Excel thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing_cols)}")
                self.finished.emit(None)
                return
            # Ensure 'recipient_phone_' and 'pv_promotion_id' are strings to handle mixed types consistently
            # self.df['recipient_phone_'] = self.df['recipient_phone_'].astype(str)
            # self.df['pv_promotion_id'] = self.df['pv_promotion_id'].astype(str)
            # self.df['buyer_id'] = self.df['buyer_id'].astype(str)
            self.log.emit("‚ÑπÔ∏è ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
            # Get all the group of > or more unique id have the same recipient_phone_ and the same pv_promotion_id
            # Ensure 'pv_promotion_id' is string to handle mixed types consistently
            # Group by recipient_phone_ and pv_promotion_id
            # Then, for each group, find the number of unique buyer_id's
            df_processed = self.df.dropna(subset=['recipient_phone_', 'pv_promotion_id', 'buyer_id']).copy()

            grouped_df = df_processed.groupby(['recipient_phone_', 'pv_promotion_id'])['buyer_id'].nunique().reset_index(name='unique_buyer_ids_count')

           # Filter for groups with 3 or more unique buyer_id's
            filtered_groups = grouped_df[grouped_df['unique_buyer_ids_count'] >= 3]

            final_grouped_ids = set()

            # For each filtered group (that has 3 or more unique buyer_ids),
            # get all buyer_id's from the original DataFrame that belong to these groups.
            # This is more efficient than iterating through rows.
            if not filtered_groups.empty:
                # Merge original df with filtered groups to get all buyer_ids
                merged_df = pd.merge(
                    self.df,
                    filtered_groups[['recipient_phone_', 'pv_promotion_id']],
                    on=['recipient_phone_', 'pv_promotion_id'],
                    how='inner'
                )
                final_grouped_ids.update(merged_df['buyer_id'].unique())

            self.log.emit("‚ÑπÔ∏è ƒêang l∆∞u k·∫øt qu·∫£...")
            
            # Create a DataFrame for the final grouped IDs (single column)
            if final_grouped_ids:
                df_output_ids = pd.DataFrame(list(final_grouped_ids), columns=['ID'])
                df_output_ids.to_excel(self.output_file_path, index=False, engine='openpyxl')
                self.log.emit(f"‚úÖ ƒê√£ l∆∞u danh s√°ch ID nh√≥m theo khuy·∫øn m√£i t·∫°i: {self.output_file_path}")
            else:
                self.log.emit("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y ID n√†o ƒë·ªÉ nh√≥m theo ti√™u ch√≠ (recipient_phone_, Promotion ID, >= 3 ID).")
            
            self.finished.emit(self.df)
        except Exception as e:
            self.log.emit(f"‚ùå ƒê√£ x·∫£y ra l·ªói: {str(e)}")
            self.finished.emit(None)

class Worker3(QtCore.QThread):
    """
    L·ªõp con c·ªßa QThread ƒë·ªÉ th·ª±c hi·ªán vi·ªác c·∫°o d·ªØ li·ªáu web v√† t·∫°o t√†i li·ªáu Word trong m·ªôt lu·ªìng ri√™ng bi·ªát.
    Ph√°t t√≠n hi·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô, th√¥ng b√°o nh·∫≠t k√Ω v√† tr·∫°ng th√°i ho√†n th√†nh.
    """
    progress = QtCore.pyqtSignal(int)
    log = QtCore.pyqtSignal(str)
    finished = QtCore.pyqtSignal(object)

    def __init__(self, input_file_path, output_file_path):
        """
        Kh·ªüi t·∫°o lu·ªìng Worker.
        Args:
            input_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel ƒë·∫ßu v√†o.
            output_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file Excel k·∫øt qu·∫£.
        """
        super().__init__()
        self.input_file_path = input_file_path
        self.output_file_path = output_file_path

    def run(self):
        try:
            self.log.emit("‚ÑπÔ∏è ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ file...")
            # Get the file extension
            file_extension = os.path.splitext(self.input_file_path)[1].lower()
            if file_extension in ['.xlsx', '.xls']:
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file Excel. ƒêang ƒë·ªçc...")
                self.data = pd.read_excel(self.input_file_path, engine='openpyxl')
            elif file_extension == '.csv':
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file CSV. ƒêang ƒë·ªçc...")
                # You might want to add encoding='utf-8' or other encoding if you encounter issues
                self.data = pd.read_csv(self.input_file_path)
            else:
                self.log.emit(f"‚ùå L·ªói: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}. Vui l√≤ng ch·ªçn file Excel (.xlsx, .xls) ho·∫∑c CSV (.csv).")
                self.finished.emit(None)
                return
            self.df = pd.DataFrame(self.data)
            # self.original_df = self.df.copy()  # Keep a copy of the original DataFrame
            # self.df['buyer_id'] = self.df['buyer_id'].drop_duplicates()
            drop_column = ["grass_hour","create_time","order_id","item_name","seller_id","shop_name","status_b","buyer_user_name","buyer_email","recipient_name","buyer_shipping_address","buyer_shipping_address_district","buyer_shipping_address_city","buyer_shipping_address_state","address_modified_time_latest","sz_device","ip_checkout","gmv_vnd","pv_promotion_cap","pv_promotion_name","pv_voucher_code","pv_rebate_by_shopee_vnd","is_nuv","sv_promotion_id","sv_voucher_code","coin_earn","coin_used_cash_amt","is_fsv_nuv","origin_shipping_fee_vnd","item_rebate_vnd","item_id","is_buyer_legit","is_seller_cb_seller","is_seller_official_shop","is_seller_preferred_seller","order_sn","buyer_cancel_reason"]
            self.df = self.df.drop(columns=drop_column, errors='ignore')
            # Validate required columns
            required_columns = ['recipient_phone_', 'fsv_voucher_code', 'buyer_id']
            if not all(col in self.df.columns for col in required_columns):
                missing_cols = [col for col in required_columns if col not in self.df.columns]
                self.log.emit(f"‚ùå L·ªói: File Excel thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing_cols)}")
                self.finished.emit(None)
                return

            self.log.emit("‚ÑπÔ∏è ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
            # Get all the group of > or more unique id have the same recipient_phone_ and the same pv_promotion_id
            # Ensure 'pv_promotion_id' is string to handle mixed types consistently
            # self.df['fsv_voucher_code'] = self.df['fsv_voucher_code'].astype(str)
            # Ensure 'recipient_phone_' and 'pv_promotion_id' are strings to handle mixed types consistently
            # self.df['recipient_phone_'] = self.df['recipient_phone_'].astype(str)
            # Group by recipient_phone_ and pv_promotion_id
            # Then, for each group, find the number of unique buyer_id's
            df_processed = self.df.dropna(subset=['recipient_phone_', 'fsv_voucher_code', 'buyer_id']).copy()

            grouped_df = df_processed.groupby(['recipient_phone_', 'fsv_voucher_code'])['buyer_id'].nunique().reset_index(name='unique_buyer_ids_count')

            # Filter for groups with 3 or more unique buyer_id's
            filtered_groups = grouped_df[grouped_df['unique_buyer_ids_count'] >= 5]

            final_grouped_ids = set()

            # For each filtered group (that has 3 or more unique buyer_ids),
            # get all buyer_id's from the original DataFrame that belong to these groups.
            # This is more efficient than iterating through rows.
            if not filtered_groups.empty:
                # Merge original df with filtered groups to get all buyer_ids
                merged_df = pd.merge(
                    self.df,
                    filtered_groups[['recipient_phone_', 'fsv_voucher_code']],
                    on=['recipient_phone_', 'fsv_voucher_code'],
                    how='inner'
                )
                final_grouped_ids.update(merged_df['buyer_id'].unique())

            self.log.emit("‚ÑπÔ∏è ƒêang l∆∞u k·∫øt qu·∫£...")
            
            # Create a DataFrame for the final grouped IDs (single column)
            if final_grouped_ids:
                df_output_ids = pd.DataFrame(list(final_grouped_ids), columns=['ID'])
                df_output_ids.to_excel(self.output_file_path, index=False, engine='openpyxl')
                self.log.emit(f"‚úÖ ƒê√£ l∆∞u danh s√°ch ID nh√≥m theo khuy·∫øn m√£i t·∫°i: {self.output_file_path}")
            else:
                self.log.emit("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y ID n√†o ƒë·ªÉ nh√≥m theo ti√™u ch√≠ (recipient_phone_, fsv_voucher_code, >= 5 ID).")
            
            self.finished.emit(self.df)
        except Exception as e:
            self.log.emit(f"‚ùå ƒê√£ x·∫£y ra l·ªói: {str(e)}")
            self.finished.emit(None)
class Worker4(QtCore.QThread):
    """
    L·ªõp con c·ªßa QThread t·∫°o t√†i li·ªáu Excel trong m·ªôt lu·ªìng ri√™ng bi·ªát.
    Ph√°t t√≠n hi·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô, th√¥ng b√°o nh·∫≠t k√Ω v√† tr·∫°ng th√°i ho√†n th√†nh.
    """
    progress = QtCore.pyqtSignal(int)
    log = QtCore.pyqtSignal(str)
    finished = QtCore.pyqtSignal(object)

    def __init__(self, input_file_path, output_file_path):
        """
        Kh·ªüi t·∫°o lu·ªìng Worker.
        Args:
            input_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel ƒë·∫ßu v√†o.
            output_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file Excel k·∫øt qu·∫£.
        """
        super().__init__()
        self.input_file_path = input_file_path
        self.output_file_path = output_file_path

    def run(self):
        try:
            self.log.emit("‚ÑπÔ∏è ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ file...")
            
            # Get the file extension
            file_extension = os.path.splitext(self.input_file_path)[1].lower()
            if file_extension in ['.xlsx', '.xls']:
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file Excel. ƒêang ƒë·ªçc...")
                self.data = pd.read_excel(self.input_file_path, engine='openpyxl')
            elif file_extension == '.csv':
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file CSV. ƒêang ƒë·ªçc...")
                # You might want to add encoding='utf-8' or other encoding if you encounter issues
                self.data = pd.read_csv(self.input_file_path)
            else:
                self.log.emit(f"‚ùå L·ªói: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}. Vui l√≤ng ch·ªçn file Excel (.xlsx, .xls) ho·∫∑c CSV (.csv).")
                self.finished.emit(None)
                return

            self.df = pd.DataFrame(self.data)
            
            # Keep 'registration_time' since it's now a condition
            drop_column = ["grass_hour", "order_id", "item_name", "seller_id", "shop_name", "status_b", 
                           "buyer_user_name", "buyer_email", "recipient_phone_", "recipient_name", 
                           "buyer_shipping_address", "buyer_shipping_address_district", 
                           "buyer_shipping_address_city", "buyer_shipping_address_state", 
                           "address_modified_time_latest", "sz_device", "N3", "gmv_vnd", 
                           "pv_promotion_id", "pv_promotion_cap", "pv_promotion_name", 
                           "pv_voucher_code", "pv_rebate_by_shopee_vnd", "is_nuv", "sv_promotion_id", 
                           "sv_voucher_code", "coin_earn", "coin_used_cash_amt", "fsv_voucher_code", 
                           "is_fsv_nuv", "origin_shipping_fee_vnd", "item_rebate_vnd", "item_id", 
                           "is_buyer_legit", "is_seller_cb_seller", "is_seller_official_shop", 
                           "is_seller_preferred_seller", "order_sn", "buyer_cancel_reason", 'registration_time']
            
            self.df = self.df.drop(columns=drop_column, errors='ignore')
            
            required_columns = ['ip_checkout', 'create_time', 'buyer_id']
            if not all(col in self.df.columns for col in required_columns):
                missing_cols = [col for col in required_columns if col not in self.df.columns]
                self.log.emit(f"‚ùå L·ªói: File Excel thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing_cols)}")
                self.finished.emit(None)
                return

            self.log.emit("‚ÑπÔ∏è ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
            
            # ƒê·∫£m b·∫£o c·ªôt 'create_time' v√† 'registration_time' l√† ki·ªÉu datetime
            self.df['create_time'] = pd.to_datetime(self.df['create_time'], errors='coerce')
            
            # Filter out rows where create_time is NaT
            # If a record has NaT for create_time, it can't be part of a time-constrained group
            df_filtered = self.df.dropna(subset=['create_time']).copy()
            
            # Sort by ip_checkout and create_time for optimized searching
            # Sorting by create_time primarily and then registration_time secondarily
            # ensures that for each ip_checkout, records are processed chronologically
            # by create_time, and then by registration_time if create_times are identical.
            # This is important for the 'start_time' and 'start_reg_time' logic.
            df_sorted = df_filtered.sort_values(by=['ip_checkout', 'create_time']).reset_index(drop=True)

            final_grouped_ids = set() # To store all unique IDs that belong to any valid group
            
            total_unique_ips = len(df_sorted['ip_checkout'].unique())
            processed_ips = 0

            # Iterate through each unique ip_checkout group
            for ip_checkout_val, group in df_sorted.groupby('ip_checkout'):
                processed_ips += 1
                self.progress.emit(int((processed_ips / total_unique_ips) * 100))

                records_for_ip = group.to_dict('records')
                
                i = 0
                while i < len(records_for_ip):
                    start_record = records_for_ip[i]
                    start_create_time = start_record['create_time']

                    current_potential_group_ids = [start_record['buyer_id']]
                    
                    j = i + 1
                    while j < len(records_for_ip):
                        next_record = records_for_ip[j]
                        next_create_time = next_record['create_time']
                        next_registration_time = next_record['registration_time']

                        # Check if BOTH create_time are within 1 hour of their respective start times
                        if (next_create_time - start_create_time) <= timedelta(hours=1) <= timedelta(hours=1):
                            current_potential_group_ids.append(next_record['buyer_id'])
                            j += 1
                        else:
                            # If either time condition fails, stop extending the current group
                            break 
                    
                    unique_ids_in_group = set(current_potential_group_ids)
                    if len(unique_ids_in_group) >= 3:
                        final_grouped_ids.update(unique_ids_in_group)
                    
                    i += 1 # Move to the next potential starting record

            self.log.emit("‚ÑπÔ∏è ƒêang l∆∞u k·∫øt qu·∫£...")
            
            # Create a DataFrame for the final grouped IDs (single column)
            if final_grouped_ids:
                df_output_ids = pd.DataFrame(list(final_grouped_ids), columns=['ID'])
                df_output_ids.to_excel(self.output_file_path, index=False, engine='openpyxl')
                self.log.emit(f"‚úÖ ƒê√£ l∆∞u danh s√°ch ID nh√≥m t·∫°i: {self.output_file_path}")
            else:
                self.log.emit("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y ID n√†o ƒë·ªÉ nh√≥m theo ti√™u ch√≠ (√≠t nh·∫•t 3 ID ri√™ng bi·ªát trong 1 gi·ªù cho c·∫£ create_time v√† registration_time).")
            
            self.finished.emit(True) # Indicate successful completion
            
        except FileNotFoundError:
            self.log.emit(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file t·∫°i ƒë∆∞·ªùng d·∫´n: {self.input_file_path}")
            self.finished.emit(None)
        except Exception as e:
            self.log.emit(f"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
            self.finished.emit(None)
class Worker5(QtCore.QThread):
    """
    L·ªõp con c·ªßa QThread t·∫°o t√†i li·ªáu Excel trong m·ªôt lu·ªìng ri√™ng bi·ªát.
    Ph√°t t√≠n hi·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô, th√¥ng b√°o nh·∫≠t k√Ω v√† tr·∫°ng th√°i ho√†n th√†nh.
    """
    progress = QtCore.pyqtSignal(int)
    log = QtCore.pyqtSignal(str)
    finished = QtCore.pyqtSignal(object)

    def __init__(self, input_file_path, output_file_path):
        """
        Kh·ªüi t·∫°o lu·ªìng Worker.
        Args:
            input_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel ƒë·∫ßu v√†o.
            output_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file Excel k·∫øt qu·∫£.
        """
        super().__init__()
        self.input_file_path = input_file_path
        self.output_file_path = output_file_path

    def run(self):
        try:
            self.log.emit("‚ÑπÔ∏è ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ file...")
            
            # Get the file extension
            file_extension = os.path.splitext(self.input_file_path)[1].lower()
            if file_extension in ['.xlsx', '.xls']:
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file Excel. ƒêang ƒë·ªçc...")
                self.data = pd.read_excel(self.input_file_path, engine='openpyxl')
            elif file_extension == '.csv':
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file CSV. ƒêang ƒë·ªçc...")
                # You might want to add encoding='utf-8' or other encoding if you encounter issues
                self.data = pd.read_csv(self.input_file_path)
            else:
                self.log.emit(f"‚ùå L·ªói: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}. Vui l√≤ng ch·ªçn file Excel (.xlsx, .xls) ho·∫∑c CSV (.csv).")
                self.finished.emit(None)
                return

            self.df = pd.DataFrame(self.data)
            
            # Keep 'registration_time' since it's now a condition
            drop_column = ["grass_hour", "order_id", "item_name", "seller_id", "shop_name", "status_b", 
                           "buyer_user_name", "buyer_email", "recipient_phone_", "recipient_name", 
                           "buyer_shipping_address", "buyer_shipping_address_district", 
                           "buyer_shipping_address_city", "buyer_shipping_address_state", 
                           "address_modified_time_latest", "sz_device", "N3", "gmv_vnd", 
                           "pv_promotion_id", "pv_promotion_cap", "pv_promotion_name", 
                           "pv_voucher_code", "pv_rebate_by_shopee_vnd", "is_nuv", "sv_promotion_id", 
                           "sv_voucher_code", "coin_earn", "coin_used_cash_amt", "fsv_voucher_code", 
                           "is_fsv_nuv", "origin_shipping_fee_vnd", "item_rebate_vnd", "item_id", 
                           "is_buyer_legit", "is_seller_cb_seller", "is_seller_official_shop", 
                           "is_seller_preferred_seller", "order_sn", "buyer_cancel_reason"]
            
            self.df = self.df.drop(columns=drop_column, errors='ignore')
            
            # Add 'registration_time' to required columns
            required_columns = ['ip_checkout', 'create_time', 'buyer_id']
            if not all(col in self.df.columns for col in required_columns):
                missing_cols = [col for col in required_columns if col not in self.df.columns]
                self.log.emit(f"‚ùå L·ªói: File Excel thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing_cols)}")
                self.finished.emit(None)
                return

            self.log.emit("‚ÑπÔ∏è ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
            
            # ƒê·∫£m b·∫£o c·ªôt 'create_time' v√† 'registration_time' l√† ki·ªÉu datetime
            self.df['create_time'] = pd.to_datetime(self.df['create_time'], errors='coerce')
            self.df['registration_time'] = pd.to_datetime(self.df['registration_time'], errors='coerce')
            
            # Filter out rows where create_time or registration_time is NaT
            # If a record has NaT for either, it can't be part of a time-constrained group
            df_filtered = self.df.dropna(subset=['create_time', 'registration_time']).copy()
            
            # Sort by ip_checkout and create_time for optimized searching
            # Sorting by create_time primarily and then registration_time secondarily
            # ensures that for each ip_checkout, records are processed chronologically
            # by create_time, and then by registration_time if create_times are identical.
            # This is important for the 'start_time' and 'start_reg_time' logic.
            df_sorted = df_filtered.sort_values(by=['ip_checkout', 'create_time', 'registration_time']).reset_index(drop=True)

            final_grouped_ids = set() # To store all unique IDs that belong to any valid group
            
            total_unique_ips = len(df_sorted['ip_checkout'].unique())
            processed_ips = 0

            # Iterate through each unique ip_checkout group
            for ip_checkout_val, group in df_sorted.groupby('ip_checkout'):
                processed_ips += 1
                self.progress.emit(int((processed_ips / total_unique_ips) * 100))

                records_for_ip = group.to_dict('records')
                
                i = 0
                while i < len(records_for_ip):
                    start_record = records_for_ip[i]
                    start_create_time = start_record['create_time']
                    start_registration_time = start_record['registration_time']

                    current_potential_group_ids = [start_record['buyer_id']]
                    
                    j = i + 1
                    while j < len(records_for_ip):
                        next_record = records_for_ip[j]
                        next_create_time = next_record['create_time']
                        next_registration_time = next_record['registration_time']

                        # Check if BOTH create_time and registration_time are within 1 hour of their respective start times
                        if (next_create_time - start_create_time) <= timedelta(hours=1) and \
                           (next_registration_time - start_registration_time) <= timedelta(hours=1):
                            current_potential_group_ids.append(next_record['buyer_id'])
                            j += 1
                        else:
                            # If either time condition fails, stop extending the current group
                            break 
                    
                    unique_ids_in_group = set(current_potential_group_ids)
                    if len(unique_ids_in_group) >= 3:
                        final_grouped_ids.update(unique_ids_in_group)
                    
                    i += 1 # Move to the next potential starting record

            self.log.emit("‚ÑπÔ∏è ƒêang l∆∞u k·∫øt qu·∫£...")
            
            # Create a DataFrame for the final grouped IDs (single column)
            if final_grouped_ids:
                df_output_ids = pd.DataFrame(list(final_grouped_ids), columns=['ID'])
                df_output_ids.to_excel(self.output_file_path, index=False, engine='openpyxl')
                self.log.emit(f"‚úÖ ƒê√£ l∆∞u danh s√°ch ID nh√≥m t·∫°i: {self.output_file_path}")
            else:
                self.log.emit("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y ID n√†o ƒë·ªÉ nh√≥m theo ti√™u ch√≠ (√≠t nh·∫•t 3 ID ri√™ng bi·ªát trong 1 gi·ªù cho c·∫£ create_time v√† registration_time).")
            
            self.finished.emit(True) # Indicate successful completion
           
        except FileNotFoundError:
            self.log.emit(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file t·∫°i ƒë∆∞·ªùng d·∫´n: {self.input_file_path}")
            self.finished.emit(None)
        except Exception as e:
            self.log.emit(f"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
            self.finished.emit(None)


class Worker7(QtCore.QThread):
    """
    L·ªõp con c·ªßa QThread t·∫°o t√†i li·ªáu Excel trong m·ªôt lu·ªìng ri√™ng bi·ªát.
    Ph√°t t√≠n hi·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô, th√¥ng b√°o nh·∫≠t k√Ω v√† tr·∫°ng th√°i ho√†n th√†nh.
    """
    progress = QtCore.pyqtSignal(int)
    log = QtCore.pyqtSignal(str)
    finished = QtCore.pyqtSignal(object)

    def __init__(self, input_file_path, output_file_path):
        """
        Kh·ªüi t·∫°o lu·ªìng Worker.
        Args:
            input_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel ƒë·∫ßu v√†o.
            output_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file Excel k·∫øt qu·∫£.
        """
        super().__init__()
        self.input_file_path = input_file_path
        self.output_file_path = output_file_path
    def _normalize_phone_number(self, phone):
        """Normalizes phone numbers to a consistent format (digits only)."""
        if pd.isna(phone):
            return None
        # Remove non-digit characters
        normalized_phone = re.sub(r'\D', '', str(phone))
        # Handle common prefixes if necessary, e.g., '84' for Vietnam
        # For simplicity, we'll keep it as just digits for exact matching.
        return normalized_phone if normalized_phone else None
    
    
    def run(self):
        try:
            self.log.emit("‚ÑπÔ∏è ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ file...")
            
            # Get the file extension
            file_extension = os.path.splitext(self.input_file_path)[1].lower()
            if file_extension in ['.xlsx', '.xls']:
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file Excel. ƒêang ƒë·ªçc...")
                self.data = pd.read_excel(self.input_file_path, engine='openpyxl')
            elif file_extension == '.csv':
                self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file CSV. ƒêang ƒë·ªçc...")
                # You might want to add encoding='utf-8' or other encoding if you encounter issues
                self.data = pd.read_csv(self.input_file_path)
            else:
                self.log.emit(f"‚ùå L·ªói: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}. Vui l√≤ng ch·ªçn file Excel (.xlsx, .xls) ho·∫∑c CSV (.csv).")
                self.finished.emit(None)
                return
            
            self.df = pd.DataFrame(self.data)
            
            # Keep 'registration_time' since it's now a condition
            drop_column = ["grass_hour", "order_id", "item_name", "seller_id", "shop_name", "status_b", 
                           "buyer_user_name", "buyer_email", "recipient_name", 
                           "buyer_shipping_address", "buyer_shipping_address_district", 
                           "buyer_shipping_address_city", "buyer_shipping_address_state", 
                           "address_modified_time_latest", "sz_device", "N3", "gmv_vnd", 
                           "pv_promotion_id", "pv_promotion_cap", "pv_promotion_name", 
                           "pv_voucher_code", "pv_rebate_by_shopee_vnd", "is_nuv", "sv_promotion_id", 
                           "sv_voucher_code", "coin_earn", "coin_used_cash_amt", "fsv_voucher_code", 
                           "is_fsv_nuv", "origin_shipping_fee_vnd", "item_rebate_vnd", "item_id", 
                           "is_buyer_legit", "is_seller_cb_seller", "is_seller_official_shop", 
                           "is_seller_preferred_seller", "order_sn", "buyer_cancel_reason"]
            
            self.df = self.df.drop(columns=drop_column, errors='ignore')
            
            # Add 'registration_time' to required columns
            required_columns = ['recipient_phone_', 'buyer_id']
            if not all(col in self.df.columns for col in required_columns):
                missing_cols = [col for col in required_columns if col not in self.df.columns]
                self.log.emit(f"‚ùå L·ªói: File Excel thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {', '.join(missing_cols)}")
                self.finished.emit(None)
                return

            self.log.emit("‚ÑπÔ∏è ƒêang chu·∫©n h√≥a s·ªë ƒëi·ªán tho·∫°i...")
            self.df['normalized_phone'] = self.df['recipient_phone_'].apply(self._normalize_phone_number)
            
            self.df.dropna(subset=['normalized_phone'], inplace=True)
            if self.df.empty:
                self.log.emit("‚ÑπÔ∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi chu·∫©n h√≥a s·ªë ƒëi·ªán tho·∫°i.")
                self.finished.emit(None)
                return
            
            final_grouped_ids = set()
            
            # Group by normalized phone number
            total_unique_phones = len(self.df['normalized_phone'].unique())
            processed_phones = 0

            # self.log.emit("‚ÑπÔ∏è B·∫Øt ƒë·∫ßu nh√≥m theo s·ªë ƒëi·ªán tho·∫°i...")

            for phone_number, group in self.df.groupby('normalized_phone'):
                processed_phones += 1
                self.progress.emit(int((processed_phones / total_unique_phones) * 100))

                unique_buyer_ids_in_group = set(group['buyer_id'].tolist())
                
                # Check if the group has 4 or more unique buyer IDs
                if len(unique_buyer_ids_in_group) >= 4:
                    final_grouped_ids.update(unique_buyer_ids_in_group)
                    # self.log.emit(f"‚úÖ T√¨m th·∫•y nh√≥m h·ª£p l·ªá cho s·ªë ƒëi·ªán tho·∫°i '{phone_number}': {len(unique_buyer_ids_in_group)} ID duy nh·∫•t.")

            self.log.emit("‚ÑπÔ∏è ƒêang l∆∞u k·∫øt qu·∫£...")
            
            if final_grouped_ids:
                df_output_ids = pd.DataFrame(list(final_grouped_ids), columns=['buyer_id'])
                df_output_ids.to_excel(self.output_file_path, index=False, engine='openpyxl')
                self.log.emit(f"‚úÖ ƒê√£ l∆∞u danh s√°ch ID nh√≥m t·∫°i: {self.output_file_path}")
            else:
                self.log.emit("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y ID n√†o ƒë·ªÉ nh√≥m theo ti√™u ch√≠ (√≠t nh·∫•t 4 ID ri√™ng bi·ªát c√≥ c√πng s·ªë ƒëi·ªán tho·∫°i).")
            
            self.finished.emit(True) 
            
        except FileNotFoundError:
            self.log.emit(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file t·∫°i ƒë∆∞·ªùng d·∫´n: {self.input_file_path}")
            self.finished.emit(None)
        except Exception as e:
            self.log.emit(f"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
            self.finished.emit(None)
# class Worker6(QtCore.QThread):
#     """
#     L·ªõp con c·ªßa QThread t·∫°o t√†i li·ªáu Excel trong m·ªôt lu·ªìng ri√™ng bi·ªát
#     d·ª±a tr√™n t√™n ng∆∞·ªùi nh·∫≠n t∆∞∆°ng t·ª± v√† qu·∫≠n ƒë·ªãa ch·ªâ giao h√†ng T∆Ø∆†NG T·ª∞ (fuzzy matching),
#     s·ª≠ d·ª•ng k·ªπ thu·∫≠t Blocking ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t.
#     Ph√°t t√≠n hi·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn ƒë·ªô, th√¥ng b√°o nh·∫≠t k√Ω v√† tr·∫°ng th√°i ho√†n th√†nh.
#     """
#     progress = QtCore.pyqtSignal(int)
#     log = QtCore.pyqtSignal(str)
#     finished = QtCore.pyqtSignal(object)

#     ADDRESS_SIMILARITY_THRESHOLD = 85 # Adjust this value (0-100)
#     NAME_BLOCKING_LENGTH = 3 # Number of characters for name blocking
#     ADDRESS_BLOCKING_WORDS = 2 # Number of words for address blocking (after cleaning)

#     def __init__(self, input_file_path, output_file_path):
#         super().__init__()
#         self.input_file_path = input_file_path
#         self.output_file_path = output_file_path

#     def _normalize_recipient_name(self, text):
#         if pd.isna(text):
#             return None
#         text = str(text).lower()
#         text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')
#         text = re.sub(r'[^a-z0-9\s]', '', text)
#         text = re.sub(r'\s+', ' ', text).strip()
#         return text

#     def _clean_address_for_fuzzy_match(self, address):
#         if pd.isna(address):
#             return None
#         text = str(address).lower()
#         text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')

#         noise_words = [
#             r'\bs·ªë\s+nh√†\b', r'\bng√µ\b', r'\bƒë∆∞·ªùng\b', r'\bth√¥n\b', r'\bt·ªï\b', r'\bkhu\s+ph·ªë\b',
#             r'\b·∫•p\b', r'\bkdc\b', r'\bch·ª£\b', r'\btr∆∞·ªùng\b', r'\bqu√°n\b', r'\bh·ªôi\s+tr∆∞·ªùng\b',
#             r'\bnh√†\s+vƒÉn\s+ho√°\b', r'\bƒë·ªôi\b', r'\bb·∫£n\b', r'\bkhu\s+d√¢n\s+c∆∞\b',
#             r'\bch√¢n\s+d·ªëc\b', r'\bƒë√®o\b', r'\bng√£\s+ba\b', r'\bto√†\s+nh√†\b', r'\bph∆∞·ªùng\b',
#             r'\btownship\b', r'\bvillage\b', r'\bhamlet\b', r'\bstreet\b', r'\bhouse\b',
#             r'\bx√≥m\b', r'\bkp\b', r'\bcty\b', r'\bc√¥ng\s+ty\b', r'\bchi\s+nh√°nh\b',
#             r'\bchi\s+c·ª•c\b', r'\bc√¥ng\s+vi√™n\b', r'\bkho\b', r'\bx∆∞·ªüng\b', r'\bkcn\b', # Industrial park
#             r'\bkhu\s+c√¥ng\s+nghi·ªáp\b'
#         ]
        
#         text = re.sub(r'^\s*(so|s)\s+\d+[a-z]?\s*,?\s*', '', text) # "so 42," "s 8a"
#         text = re.sub(r'\([^)]*\)', '', text) # Remove parentheses
#         text = re.sub(r'[.,;]', '', text) # Remove common separators

#         for noise in noise_words:
#             text = re.sub(noise, ' ', text)

#         text = re.sub(r'\s+', ' ', text).strip() # Consolidate spaces
#         text = re.sub(r'[^a-z0-9\s]', '', text) # Final non-alphanumeric removal
#         text = re.sub(r'\s+', ' ', text).strip()

#         return text if text else None

#     def run(self):
#         try:
#             self.log.emit("‚ÑπÔ∏è ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ file...")
            
#             file_extension = os.path.splitext(self.input_file_path)[1].lower()
#             if file_extension in ['.xlsx', '.xls']:
#                 self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file Excel. ƒêang ƒë·ªçc...")
#                 self.df = pd.read_excel(self.input_file_path, engine='openpyxl')
#             elif file_extension == '.csv':
#                 self.log.emit("‚ÑπÔ∏è Ph√°t hi·ªán file CSV. ƒêang ƒë·ªçc...")
#                 self.df = pd.read_csv(self.input_file_path)
#             else:
#                 self.log.emit(f"‚ùå L·ªói: ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}. Vui l√≤ng ch·ªçn file Excel (.xlsx, .xls) ho·∫∑c CSV (.csv).")
#                 self.finished.emit(None)
#                 return

#             self.log.emit("‚ÑπÔ∏è ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
            
#             required_columns = ['buyer_id', 'recipient_name', 'buyer_shipping_address_district']
#             if not all(col in self.df.columns for col in required_columns):
#                 missing_cols = [col for col in required_columns if col not in self.df.columns]
#                 self.log.emit(f"‚ùå L·ªói: File thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc cho b√°o c√°o n√†y: {', '.join(missing_cols)}")
#                 self.finished.emit(None)
#                 return

#             self.df.dropna(subset=required_columns, inplace=True)
#             if self.df.empty:
#                 self.log.emit("‚ÑπÔ∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi lo·∫°i b·ªè c√°c h√†ng thi·∫øu th√¥ng tin b·∫Øt bu·ªôc.")
#                 self.finished.emit(None)
#                 return

#             self.log.emit("‚ÑπÔ∏è ƒêang chu·∫©n h√≥a t√™n ng∆∞·ªùi nh·∫≠n v√† ƒë·ªãa ch·ªâ...")
#             self.df['normalized_recipient_name'] = self.df['recipient_name'].apply(self._normalize_recipient_name)
#             self.df['cleaned_address'] = self.df['buyer_shipping_address_district'].apply(self._clean_address_for_fuzzy_match)

#             self.df.dropna(subset=['normalized_recipient_name', 'cleaned_address'], inplace=True)
#             if self.df.empty:
#                 self.log.emit("‚ÑπÔ∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi chu·∫©n h√≥a.")
#                 self.finished.emit(None)
#                 return

#             # --- Blocking Step for improved performance ---
#             self.log.emit("‚ÑπÔ∏è ƒêang t·∫°o c√°c kh·ªëi (block) d·ªØ li·ªáu ƒë·ªÉ so s√°nh hi·ªáu qu·∫£ h∆°n...")
            
#             # Create a unique ID for each original row, to easily refer back to it
#             self.df['original_index'] = self.df.index 
            
#             # Use 'records' for efficient iteration in Python loop
#             records = self.df[['original_index', 'normalized_recipient_name', 'cleaned_address', 'buyer_id']].to_dict('records')
            
#             # The hashmap/dictionary for blocking
#             # Key: (name_block, address_block) -> Value: list of record_dicts
#             blocks = {}

#             for record in records:
#                 # Create blocking keys (e.g., first few chars/words)
#                 name_block = record['normalized_recipient_name'][:self.NAME_BLOCKING_LENGTH] if record['normalized_recipient_name'] else ''
#                 address_words = record['cleaned_address'].split() if record['cleaned_address'] else []
#                 address_block = " ".join(address_words[:self.ADDRESS_BLOCKING_WORDS])

#                 blocking_key = (name_block, address_block)
                
#                 if blocking_key not in blocks:
#                     blocks[blocking_key] = []
#                 blocks[blocking_key].append(record)

#             self.log.emit(f"‚ÑπÔ∏è ƒê√£ t·∫°o {len(blocks)} kh·ªëi d·ªØ li·ªáu.")
#             # --- End Blocking Step ---

#             final_grouped_buyer_ids = set()
            
#             # To keep track of which original_indices have been added to a final group
#             processed_original_indices = set() 

#             total_blocks = len(blocks)
#             processed_blocks_count = 0

#             self.log.emit("‚ÑπÔ∏è B·∫Øt ƒë·∫ßu ph√¢n t√≠ch nh√≥m trong t·ª´ng kh·ªëi...")

#             for blocking_key, block_records in blocks.items():
#                 processed_blocks_count += 1
#                 self.progress.emit(int((processed_blocks_count / total_blocks) * 100))

#                 # If a block is too small, it can't meet the >=3 unique buyer_id criteria anyway
#                 if len(block_records) < 3:
#                     continue

#                 # Within each block, perform pairwise fuzzy comparison
#                 # We need to ensure we don't re-process records that were already grouped *in this block*
#                 # and efficiently find all members of a cluster.
                
#                 # A simple clustering within a block:
#                 # Iterate through each record in the block as a potential cluster centroid
                
#                 # Use a local set for this block to manage processed records
#                 block_processed_record_indices = set() 

#                 for i in range(len(block_records)):
#                     current_record_in_block = block_records[i]
#                     current_original_index = current_record_in_block['original_index']

#                     # Skip if this record has already been part of a group formed in this block, or a global group
#                     if current_original_index in block_processed_record_indices or \
#                        current_original_index in processed_original_indices:
#                         continue
                    
#                     current_name = current_record_in_block['normalized_recipient_name']
#                     current_address = current_record_in_block['cleaned_address']
                    
#                     # This list will hold the original_indices of records belonging to the current cluster
#                     current_cluster_original_indices = [current_original_index]
#                     current_cluster_buyer_ids = [current_record_in_block['buyer_id']]

#                     # Compare this record with all subsequent records in the block
#                     for j in range(i + 1, len(block_records)):
#                         other_record_in_block = block_records[j]
#                         other_original_index = other_record_in_block['original_index']

#                         if other_original_index in block_processed_record_indices or \
#                            other_original_index in processed_original_indices:
#                             continue

#                         other_name = other_record_in_block['normalized_recipient_name']
#                         other_address = other_record_in_block['cleaned_address']

#                         name_similarity = fuzz.ratio(current_name, other_name)
#                         address_similarity = fuzz.token_sort_ratio(current_address, other_address)

#                         if name_similarity >= self.ADDRESS_SIMILARITY_THRESHOLD and \
#                            address_similarity >= self.ADDRESS_SIMILARITY_THRESHOLD:
                            
#                             current_cluster_original_indices.append(other_original_index)
#                             current_cluster_buyer_ids.append(other_record_in_block['buyer_id'])
                    
#                     # After comparing current_record with all others in the block, evaluate the cluster
#                     unique_ids_in_cluster = set(current_cluster_buyer_ids)
                    
#                     if len(unique_ids_in_cluster) >= 3:
#                         # Add these buyer IDs to the final set
#                         final_grouped_buyer_ids.update(unique_ids_in_cluster)
                        
#                         # Mark these records as processed to avoid re-clustering them as a starting point
#                         processed_original_indices.update(current_cluster_original_indices)
#                         block_processed_record_indices.update(current_cluster_original_indices)
#                         self.log.emit(f"‚úÖ T√¨m th·∫•y nh√≥m h·ª£p l·ªá trong kh·ªëi '{blocking_key}': {len(unique_ids_in_cluster)} ID duy nh·∫•t.")

#             self.log.emit("‚ÑπÔ∏è ƒêang l∆∞u k·∫øt qu·∫£...")
            
#             if final_grouped_buyer_ids:
#                 df_output_ids = pd.DataFrame(list(final_grouped_buyer_ids), columns=['buyer_id'])
#                 df_output_ids.to_excel(self.output_file_path, index=False, engine='openpyxl')
#                 self.log.emit(f"‚úÖ ƒê√£ l∆∞u danh s√°ch ID nh√≥m t·∫°i: {self.output_file_path}")
#             else:
#                 self.log.emit("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y ID n√†o ƒë·ªÉ nh√≥m theo ti√™u ch√≠ (√≠t nh·∫•t 3 ID ri√™ng bi·ªát v·ªõi t√™n/qu·∫≠n t∆∞∆°ng ƒë·ªìng).")
            
#             self.finished.emit(True)
            
#         except FileNotFoundError:
#             self.log.emit(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file t·∫°i ƒë∆∞·ªùng d·∫´n: {self.input_file_path}")
#             self.finished.emit(None)
#         except Exception as e:
#             self.log.emit(f"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
#             self.finished.emit(None)
class Ui_MainWindow(object):
    """
    L·ªõp UI ch√≠nh cho ·ª©ng d·ª•ng PyQt6.
    Thi·∫øt l·∫≠p c·ª≠a s·ªï ch√≠nh, c√°c widget, b·ªë c·ª•c v√† k·∫øt n·ªëi t√≠n hi·ªáu/khe.
    """
    def setupUi(self, MainWindow):
        """
        Thi·∫øt l·∫≠p giao di·ªán ng∆∞·ªùi d√πng cho c·ª≠a s·ªï ch√≠nh.
        Args:
            MainWindow (QtWidgets.QMainWindow): ƒê·ªëi t∆∞·ª£ng c·ª≠a s·ªï ch√≠nh.
        """
        MainWindow.setObjectName("MainWindow")
        MainWindow.setMinimumSize(QtCore.QSize(620, 720))
        MainWindow.showMaximized()
        self.main_window = MainWindow
        
        # Initial stylesheet (light mode)
        self.light_mode_stylesheet = """
            QWidget {
                background-color: #fce4ec; /* Light Pink - Background */
                font-family: 'Segoe UI';
                color: #ad1457; /* Darker Pink - Default Text */
            }
            QPushButton {
                background-color: #e91e63; /* Deep Pink - Buttons */
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 8px;
                font-size: 14px;
                font-weight: 600;
            }
            QPushButton:hover {
                background-color: #c2185b; /* Darker Deep Pink - Button Hover */
            }
            QLineEdit, QTextEdit {
                background-color: #ffffff; /* White - Input Fields */
                border: 2px solid #f8bbd0; /* Light Pink Border */
                border-radius: 8px;
                padding: 6px;
                font-size: 13px;
                color: #4a148c; /* Dark Purple for text in light mode inputs */
            }
            QLabel {
                color: #ad1457; /* Darker Pink - Labels */
                font-size: 13pt;
            }
            QProgressBar {
                height: 24px;
                border-radius: 8px;
                background: #f8bbd0; /* Light Pink - Progress Bar Background */
            }
            QProgressBar::chunk {
                background-color: #e91e63; /* Deep Pink - Progress Bar Chunk */
                border-radius: 8px;
                transition: all 0.5s ease-in-out;
            }
            QTabWidget::pane {
                border: 2px solid #f8bbd0; /* Light Pink Border - Tab Pane */
                border-radius: 8px;
                background: #ffffff; /* White - Tab Pane Background */
                margin-top: 10px;
            }
            QTabBar::tab {
                background: #f8bbd0; /* Light Pink - Tab Background */
                border: 2px solid #f8bbd0;
                border-radius: 8px;
                padding: 8px 20px;
                font-size: 13px;
                color: #ad1457; /* Darker Pink - Tab Text */
            }
            QTabBar::tab:selected {
                background: #e91e63; /* Deep Pink - Selected Tab */
                color: white;
                font-weight: bold;
            }
            QTabBar::tab:hover {
                background: #f48fb1; /* Medium Pink - Tab Hover */
            }
            QTableWidget {
                background-color: #ffffff; /* White - Table Background */
                border: 2px solid #f8bbd0; /* Light Pink Border */
                border-radius: 8px;
                gridline-color: #f8bbd0; /* Light Pink Grid Lines */
                font-size: 13px;
                selection-background-color: #f48fb1; /* Medium Pink - Selection */
                selection-color: #ad1457; /* Darker Pink - Selected Text */
            }
            QTableWidget::item {
                padding: 6px;
            }
            QHeaderView::section {
                background-color: #f8bbd0; /* Light Pink - Header Background */
                color: #ad1457; /* Darker Pink - Header Text */
                padding: 6px;
                font-weight: bold;
                font-size: 13px;
                border: 1px solid #f48fb1; /* Medium Pink Border */
            }
            QTableCornerButton::section {
                background-color: #f8bbd0; /* Light Pink - Corner Button */
                border: 1px solid #f48fb1;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #fce4ec; /* Light Pink - Scrollbar Background */
                border: none;
                width: 12px;
                height: 12px;
            }
            QScrollBar::handle:vertical, QScrollBar::handle:horizontal {
                background: #e91e63; /* Deep Pink - Scrollbar Handle */
                border-radius: 6px;
            }
            QScrollBar::add-line, QScrollBar::sub-line {
                background: none;
                border: none;
            }
            /* Style for the title label */
            #titleLabel {
                font-size: 28pt;
                font-weight: bold;
                color: #880e4f; /* Even darker pink */
                padding-bottom: 10px;
            }
            /* Styles for the dark mode toggle switch (checkbox) */
            QCheckBox::indicator {
                width: 25px;
                height: 25px;
                border-radius: 12px;
            }
            QCheckBox::indicator:unchecked {
                background-color: #f48fb1; /* Medium Pink - Unchecked */
                border: 1px solid #e91e63;
            }
            QCheckBox::indicator:unchecked:hover {
                background-color: #e91e63;
            }
            QCheckBox::indicator:checked {
                background-color: #4a148c; /* Dark Purple - Checked */
                border: 1px solid #ad1457;
            }
            QCheckBox::indicator:checked:hover {
                background-color: #6a1b9a;
            }
        """

        self.dark_mode_stylesheet = """
            QWidget {
                background-color: #263238; /* Dark Blue Grey - Background */
                font-family: 'Segoe UI';
                color: #eceff1; /* Light Grey - Default Text */
            }
            QPushButton {
                background-color: #8e24aa; /* Dark Purple - Buttons */
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 8px;
                font-size: 14px;
                font-weight: 600;
            }
            QPushButton:hover {
                background-color: #6a1b9a; /* Darker Purple - Button Hover */
            }
            QLineEdit, QTextEdit {
                background-color: #37474f; /* Even Darker Blue Grey - Input Fields */
                border: 2px solid #546e7a; /* Grey Blue Border */
                border-radius: 8px;
                padding: 6px;
                font-size: 13px;
                color: #e0f2f7; /* Lighter Blue for text in dark mode inputs */
            }
            QLabel {
                color: #b39ddb; /* Light Purple - Labels */
                font-size: 13pt;
            }
            QProgressBar {
                height: 24px;
                border-radius: 8px;
                background: #546e7a; /* Grey Blue - Progress Bar Background */
            }
            QProgressBar::chunk {
                background-color: #ab47bc; /* Medium Purple - Progress Bar Chunk */
                border-radius: 8px;
                transition: all 0.5s ease-in-out;
            }
            QTabWidget::pane {
                border: 2px solid #546e7a; /* Grey Blue Border - Tab Pane */
                border-radius: 8px;
                background: #37474f; /* Darker Blue Grey - Tab Pane Background */
                margin-top: 10px;
            }
            QTabBar::tab {
                background: #546e7a; /* Grey Blue - Tab Background */
                border: 2px solid #546e7a;
                border-radius: 8px;
                padding: 8px 20px;
                font-size: 13px;
                color: #cfd8dc; /* Light Grey - Tab Text */
            }
            QTabBar::tab:selected {
                background: #8e24aa; /* Dark Purple - Selected Tab */
                color: white;
                font-weight: bold;
            }
            QTabBar::tab:hover {
                background: #7b1fa2; /* Slightly Darker Purple - Tab Hover */
            }
            QTableWidget {
                background-color: #37474f; /* Darker Blue Grey - Table Background */
                border: 2px solid #546e7a; /* Grey Blue Border */
                border-radius: 8px;
                gridline-color: #546e7a; /* Grey Blue Grid Lines */
                font-size: 13px;
                selection-background-color: #ab47bc; /* Medium Purple - Selection */
                selection-color: white; /* White - Selected Text */
            }
            QTableWidget::item {
                padding: 6px;
            }
            QHeaderView::section {
                background-color: #546e7a; /* Grey Blue - Header Background */
                color: #b39ddb; /* Light Purple - Header Text */
                padding: 6px;
                font-weight: bold;
                font-size: 13px;
                border: 1px solid #78909c; /* Medium Grey Blue Border */
            }
            QTableCornerButton::section {
                background-color: #546e7a; /* Grey Blue - Corner Button */
                border: 1px solid #78909c;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #263238; /* Dark Blue Grey - Scrollbar Background */
                border: none;
                width: 12px;
                height: 12px;
            }
            QScrollBar::handle:vertical, QScrollBar::handle:horizontal {
                background: #8e24aa; /* Dark Purple - Scrollbar Handle */
                border-radius: 6px;
            }
            QScrollBar::add-line, QScrollBar::sub-line {
                background: none;
                border: none;
            }
            /* Style for the title label */
            #titleLabel {
                font-size: 28pt;
                font-weight: bold;
                color: #d1c4e9; /* Lighter purple */
                padding-bottom: 10px;
            }
            /* Styles for the dark mode toggle switch (checkbox) */
            QCheckBox::indicator {
                width: 25px;
                height: 25px;
                border-radius: 12px;
            }
            QCheckBox::indicator:unchecked {
                background-color: #546e7a; /* Grey Blue - Unchecked */
                border: 1px solid #8e24aa;
            }
            QCheckBox::indicator:unchecked:hover {
                background-color: #6a1b9a;
            }
            QCheckBox::indicator:checked {
                background-color: #b39ddb; /* Light Purple - Checked */
                border: 1px solid #8e24aa;
            }
            QCheckBox::indicator:checked:hover {
                background-color: #d1c4e9;
            }
        """
        self.is_dark_mode = False # Track current mode
        MainWindow.setStyleSheet(self.light_mode_stylesheet) # Apply initial stylesheet

        self.centralwidget = QtWidgets.QWidget(MainWindow)
        main_layout = QtWidgets.QVBoxLayout(self.centralwidget)
        main_layout.setContentsMargins(20, 20, 20, 20)
        main_layout.setSpacing(15)


        # --- Dark Mode Toggle ---
        dark_mode_layout = QtWidgets.QHBoxLayout()
        dark_mode_layout.addStretch() # Push toggle to the right
        self.dark_mode_checkbox = QtWidgets.QCheckBox("Dark Mode")
        self.dark_mode_checkbox.setFont(QtGui.QFont("Segoe UI", 11))
        self.dark_mode_checkbox.setStyleSheet("QCheckBox { color: #ad1457; }") # Initial color for light mode
        self.dark_mode_checkbox.stateChanged.connect(self.toggle_dark_mode)
        dark_mode_layout.addWidget(self.dark_mode_checkbox)
        main_layout.addLayout(dark_mode_layout)

        self.tabWidget = QtWidgets.QTabWidget()
        main_layout.addWidget(self.tabWidget)

        self.tab1 = QtWidgets.QWidget()
        tab1_layout = QtWidgets.QVBoxLayout(self.tab1)
        tab1_layout.setSpacing(15)

        # --- Input/Action Grouping (Optional: Can wrap in QGroupBox if desired) ---
        # For now, just keeping the existing layouts but mentioning the concept
        label_mnv_layout = QtWidgets.QHBoxLayout()
        self.label_mnv = QtWidgets.QLabel("H√£y ch·ªçn file g·ªëc:")
        self.mnv = QtWidgets.QLineEdit()
        self.mnv.setPlaceholderText("ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel g·ªëc...")
        self.chose_file_btn = QtWidgets.QPushButton("Ch·ªçn file g·ªëc")
        self.chose_file_btn.clicked.connect(self.choose_file)
        self.mnv.setFont(QtGui.QFont("Segoe UI", 11))
        label_mnv_layout.addWidget(self.label_mnv)
        label_mnv_layout.addWidget(self.mnv)
        label_mnv_layout.addWidget(self.chose_file_btn)

        btn_layout = QtWidgets.QHBoxLayout()
        self.create_btn = QtWidgets.QPushButton("N3 Report")
        self.create_btn.clicked.connect(self.generate_report)
        self.clear_btn = QtWidgets.QPushButton("Same Promotion Report")
        self.clear_btn.clicked.connect(self.clear_input)
        self.fsv_btn = QtWidgets.QPushButton("Same FSV Report")
        self.fsv_btn.clicked.connect(self.same_fsv_input)
        self.ip_create_time_btn = QtWidgets.QPushButton("Same IP and Create Time Report")
        self.ip_create_time_btn.clicked.connect(self.same_ip_check_out)
        btn_layout.addWidget(self.create_btn)
        btn_layout.addWidget(self.clear_btn)
        btn_layout.addWidget(self.fsv_btn)
        btn_layout.addWidget(self.ip_create_time_btn)

        btn_layout_row_2 = QtWidgets.QHBoxLayout()
        self.same_ip_reg_create_time_btn = QtWidgets.QPushButton("Same IP and Create + RegTime Report")
        self.same_ip_reg_create_time_btn.clicked.connect(self.same_ip_reg_create_time)
        self.rsl_btn = QtWidgets.QPushButton("RSL Report")
        self.rsl_btn.clicked.connect(self.rsl_report)
        btn_layout_row_2.addWidget(self.same_ip_reg_create_time_btn)
        btn_layout_row_2.addWidget(self.rsl_btn)
        self.progress_bar = QtWidgets.QProgressBar()
        self.progress_bar.setTextVisible(False)
        self.progress_bar.setValue(0)
        
        self.interactive_button = [
            self.create_btn, 
            self.clear_btn, 
            self.fsv_btn, 
            self.ip_create_time_btn, 
            self.same_ip_reg_create_time_btn,
            self.rsl_btn
        ]
        
        # self.spinner = QtWidgets.QLabel()
        # self.movie = QtGui.QMovie(resource_path("light2.gif"))
        # self.spinner.setMovie(self.movie)
        # self.spinner.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        
        
        self.log_output = QtWidgets.QTextEdit()
        self.log_output.setReadOnly(True)
        # Apply style to log output to allow rich text (for icons)
        self.log_output.document().setDefaultStyleSheet("p { margin-bottom: 2px; }")


        tab1_layout.addLayout(label_mnv_layout)
        tab1_layout.addLayout(btn_layout)
        tab1_layout.addLayout(btn_layout_row_2)
        tab1_layout.addWidget(self.progress_bar)
        tab1_layout.addWidget(self.log_output)
        # tab1_layout.addWidget(self.spinner)

        self.tabWidget.addTab(self.tab1, "Nh√≥m D·ªØ Li·ªáu")

        MainWindow.setCentralWidget(self.centralwidget)
    
    def _set_buttons_enabled(self, enabled: bool):
        """
        Helper function to enable or disable all interactive buttons.
        Args:
            enabled (bool): True to enable buttons, False to disable.
        """
        for button in self.interactive_button:
            button.setEnabled(enabled)
    def choose_file(self):
        """
        M·ªü h·ªôp tho·∫°i ƒë·ªÉ ng∆∞·ªùi d√πng ch·ªçn file Excel g·ªëc.
        L∆∞u ƒë∆∞·ªùng d·∫´n file v√†o √¥ nh·∫≠p m√£ nh√¢n vi√™n.
        """
        file_path, _ = QtWidgets.QFileDialog.getOpenFileName(
            None, "Ch·ªçn file g·ªëc", "", ";;All Files (*)")
        if file_path:
            self.mnv.setText(file_path)

    def on_report_finished(self, df):
        """
        H√†m ƒë∆∞·ª£c g·ªçi khi lu·ªìng Worker ho√†n th√†nh vi·ªác t·∫°o b√°o c√°o.
        Hi·ªÉn th·ªã th√¥ng b√°o v√† ·∫©n spinner.
        """
        self.progress_bar.setValue(100)
        if df is not None:
            self.log_output.append("‚úÖ X·ª≠ l√Ω ho√†n t·∫•t!")
        else:
            self.log_output.append("‚ö†Ô∏è Qu√° tr√¨nh x·ª≠ l√Ω kh√¥ng th√†nh c√¥ng ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ nh√≥m.")
        self._set_buttons_enabled(True)  # Re-enable buttons after processing


    def generate_report(self):
        """
        B·∫Øt ƒë·∫ßu qu√° tr√¨nh t·∫°o b√°o c√°o N3.
        Y√™u c·∫ßu ng∆∞·ªùi d√πng ch·ªçn v·ªã tr√≠ l∆∞u v√† kh·ªüi ƒë·ªông lu·ªìng Worker.
        """
        input_file_path = self.mnv.text()
        if not input_file_path:
            QtWidgets.QMessageBox.warning(None, "L·ªói", "Vui l√≤ng ch·ªçn file Excel g·ªëc.")
            return

        self.log_output.clear()
        self.progress_bar.setValue(0)
        self.log_output.append("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        self._set_buttons_enabled(False)  # Disable buttons during processing

        output_file_path, _ = QtWidgets.QFileDialog.getSaveFileName(
            None, "L∆∞u File D·ªØ Li·ªáu Nh√≥m", "du_lieu_nhom_N3.xlsx", "Excel Files (*.xlsx)")
        if not output_file_path:
            self.log_output.append("‚ùå ƒê√£ h·ªßy l∆∞u file.")
            self._set_buttons_enabled(True)  # Re-enable if cancelled
            return

        self.thread = Worker(input_file_path, output_file_path)
        self.thread.progress.connect(self.progress_bar.setValue)
        self.thread.log.connect(self.log_output.append)
        self.thread.finished.connect(self.on_report_finished)
        self.thread.start()

    def clear_input(self):
        """
        T·∫°o b√°o c√°o same promotion.
        """
        input_file_path = self.mnv.text()
        if not input_file_path:
            QtWidgets.QMessageBox.warning(None, "L·ªói", "Vui l√≤ng ch·ªçn file Excel g·ªëc.")
            return

        self.log_output.clear()
        self.progress_bar.setValue(0)
        # self.movie.start()  # Start the spinner animation
        # self.movie.stop()  # Stop the spinner animation
        self.log_output.append("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        self._set_buttons_enabled(False)

        output_file_path, _ = QtWidgets.QFileDialog.getSaveFileName(
            None, "L∆∞u File Same", "du_lieu_same_promotion.xlsx", "Excel Files (*.xlsx)")
        if not output_file_path:
            self.log_output.append("‚ùå ƒê√£ h·ªßy l∆∞u file.")
            self._set_buttons_enabled(True)
            return

        self.thread = Worker2(input_file_path, output_file_path)
        self.thread.progress.connect(self.progress_bar.setValue)
        self.thread.log.connect(self.log_output.append)
        self.thread.finished.connect(self.on_report_finished)
        self.thread.start()

    def same_fsv_input(self):
        """
        T·∫°o b√°o c√°o same fsv.
        """
        input_file_path = self.mnv.text()
        if not input_file_path:
            QtWidgets.QMessageBox.warning(None, "L·ªói", "Vui l√≤ng ch·ªçn file Excel g·ªëc.")
            return

        self.log_output.clear()
        self.progress_bar.setValue(0)
        self.log_output.append("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        self._set_buttons_enabled(False)

        output_file_path, _ = QtWidgets.QFileDialog.getSaveFileName(
            None, "L∆∞u File Same", "same_fsv.xlsx", "Excel Files (*.xlsx)")
        if not output_file_path:
            self.log_output.append("‚ùå ƒê√£ h·ªßy l∆∞u file.")
            self._set_buttons_enabled(True)
            return

        self.thread = Worker3(input_file_path, output_file_path)
        self.thread.progress.connect(self.progress_bar.setValue)
        self.thread.log.connect(self.log_output.append)
        self.thread.finished.connect(self.on_report_finished)
        self.thread.start()

    def same_ip_check_out(self):
        """
        T·∫°o b√°o c√°o same ip check out v√† create time.
        """
        input_file_path = self.mnv.text()
        if not input_file_path:
            QtWidgets.QMessageBox.warning(None, "L·ªói", "Vui l√≤ng ch·ªçn file Excel g·ªëc.")
            return

        self.log_output.clear()
        self.progress_bar.setValue(0)
        self.log_output.append("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        self._set_buttons_enabled(False)

        output_file_path, _ = QtWidgets.QFileDialog.getSaveFileName(
            None, "L∆∞u File Same", "same_fsv.xlsx", "Excel Files (*.xlsx)")
        if not output_file_path:
            self.log_output.append("‚ùå ƒê√£ h·ªßy l∆∞u file.")
            self._set_buttons_enabled(True)
            return

        self.thread = Worker4(input_file_path, output_file_path)
        self.thread.progress.connect(self.progress_bar.setValue)
        self.thread.log.connect(self.log_output.append)
        self.thread.finished.connect(self.on_report_finished)
        self.thread.start()


    def same_ip_reg_create_time(self):
        """
        T·∫°o b√°o c√°o same ip check out v√† create time.
        """
        input_file_path = self.mnv.text()
        if not input_file_path:
            QtWidgets.QMessageBox.warning(None, "L·ªói", "Vui l√≤ng ch·ªçn file Excel g·ªëc.")
            return

        self.log_output.clear()
        self.progress_bar.setValue(0)
        self.log_output.append("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        self._set_buttons_enabled(False)

        output_file_path, _ = QtWidgets.QFileDialog.getSaveFileName(
            None, "L∆∞u File Same", "same_fsv.xlsx", "Excel Files (*.xlsx)")
        if not output_file_path:
            self.log_output.append("‚ùå ƒê√£ h·ªßy l∆∞u file.")
            self._set_buttons_enabled(True)
            return

        self.thread = Worker5(input_file_path, output_file_path)
        self.thread.progress.connect(self.progress_bar.setValue)
        self.thread.log.connect(self.log_output.append)
        self.thread.finished.connect(self.on_report_finished)
        self.thread.start()


    def rsl_report(self):
        """
        T·∫°o b√°o c√°o same ip check out v√† create time.
        """
        input_file_path = self.mnv.text()
        if not input_file_path:
            QtWidgets.QMessageBox.warning(None, "L·ªói", "Vui l√≤ng ch·ªçn file Excel g·ªëc.")
            return

        self.log_output.clear()
        self.progress_bar.setValue(0)
        self.log_output.append("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        self._set_buttons_enabled(False)

        output_file_path, _ = QtWidgets.QFileDialog.getSaveFileName(
            None, "L∆∞u File Same", "same_fsv.xlsx", "Excel Files (*.xlsx)")
        if not output_file_path:
            self.log_output.append("‚ùå ƒê√£ h·ªßy l∆∞u file.")
            self._set_buttons_enabled(True)
            return

        self.thread = Worker7(input_file_path, output_file_path)
        self.thread.progress.connect(self.progress_bar.setValue)
        self.thread.log.connect(self.log_output.append)
        self.thread.finished.connect(self.on_report_finished)
        self.thread.start()


    def toggle_dark_mode(self, state):
        if state == QtCore.Qt.CheckState.Checked.value: # Dark mode is ON
            self.is_dark_mode = True
            self.main_window.setStyleSheet(self.dark_mode_stylesheet)
            # Update specific widget colors for dark mode
            self.dark_mode_checkbox.setStyleSheet("QCheckBox { color: #b39ddb; }")
            # Using objectName to target the title label specifically
            self.label_mnv.setStyleSheet("QLabel { color: #b39ddb; }")
            self.mnv.setStyleSheet("QLineEdit { color: #e0f2f7; }")
            self.log_output.setStyleSheet("QTextEdit { color: #eceff1; }") # Log output text color in dark mode

        else: # Light mode is ON
            self.is_dark_mode = False
            self.main_window.setStyleSheet(self.light_mode_stylesheet)
            # Update specific widget colors for light mode
            self.dark_mode_checkbox.setStyleSheet("QCheckBox { color: #ad1457; }")
            self.label_mnv.setStyleSheet("QLabel { color: #ad1457; }")
            self.mnv.setStyleSheet("QLineEdit { color: #4a148c; }")
            self.log_output.setStyleSheet("QTextEdit { color: #ad1457; }") # Log output text color in light mode

if __name__ == "__main__":
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    MainWindow.setWindowTitle("Grouping Tool")
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec())